<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>因果模型学习笔记</title>
  <meta name="description" content="因果模型学习笔记" />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="因果模型学习笔记" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="因果模型学习笔记" />
  
  
  

<meta name="author" content="高文欣" />


<meta name="date" content="2025-09-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path=""><a href="#le_uplift"><i class="fa fa-check"></i><b>1</b> le_uplift</a></li>
<li class="chapter" data-level="2" data-path=""><a href="#uplift-model%E4%B8%8Eresponse-model%E5%8C%BA%E5%88%AB"><i class="fa fa-check"></i><b>2</b> uplift-model与response-model区别</a></li>
<li class="chapter" data-level="3" data-path=""><a href="#%E5%9F%BA%E7%A1%80%E5%AE%9A%E4%B9%89"><i class="fa fa-check"></i><b>3</b> 基础定义</a></li>
<li class="chapter" data-level="4" data-path=""><a href="#%E6%A8%A1%E5%9E%8B"><i class="fa fa-check"></i><b>4</b> 模型</a>
<ul>
<li class="chapter" data-level="4.1" data-path=""><a href="#meta-learner"><i class="fa fa-check"></i><b>4.1</b> meta-learner</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path=""><a href="#slearner"><i class="fa fa-check"></i><b>4.1.1</b> Slearner</a></li>
<li class="chapter" data-level="4.1.2" data-path=""><a href="#tlearner"><i class="fa fa-check"></i><b>4.1.2</b> TLearner</a></li>
<li class="chapter" data-level="4.1.3" data-path=""><a href="#xlearner"><i class="fa fa-check"></i><b>4.1.3</b> XLearner</a></li>
<li class="chapter" data-level="4.1.4" data-path=""><a href="#rlearner"><i class="fa fa-check"></i><b>4.1.4</b> RLearner</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path=""><a href="#tree-base"><i class="fa fa-check"></i><b>4.2</b> Tree-base</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path=""><a href="#casusaltree"><i class="fa fa-check"></i><b>4.2.1</b> Casusaltree</a></li>
<li class="chapter" data-level="4.2.2" data-path=""><a href="#casusalforest"><i class="fa fa-check"></i><b>4.2.2</b> CasusalForest</a></li>
<li class="chapter" data-level="4.2.3" data-path=""><a href="#dml"><i class="fa fa-check"></i><b>4.2.3</b> DML</a></li>
<li class="chapter" data-level="4.2.4" data-path=""><a href="#drl"><i class="fa fa-check"></i><b>4.2.4</b> DRL</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path=""><a href="#%E6%B7%B1%E5%BA%A6%E5%9B%A0%E6%9E%9C%E6%A8%A1%E5%9E%8B"><i class="fa fa-check"></i><b>4.3</b> 深度因果模型</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path=""><a href="#tarnet"><i class="fa fa-check"></i><b>4.3.1</b> TARNET</a></li>
<li class="chapter" data-level="4.3.2" data-path=""><a href="#dragonnet"><i class="fa fa-check"></i><b>4.3.2</b> Dragonnet</a></li>
<li class="chapter" data-level="4.3.3" data-path=""><a href="#efin"><i class="fa fa-check"></i><b>4.3.3</b> EFIN</a></li>
<li class="chapter" data-level="4.3.4" data-path=""><a href="#descn"><i class="fa fa-check"></i><b>4.3.4</b> DESCN</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path=""><a href="#treatment%E7%B1%BB%E5%9E%8B"><i class="fa fa-check"></i><b>5</b> treatment类型</a>
<ul>
<li class="chapter" data-level="5.1" data-path=""><a href="#%E4%BA%8C%E5%85%83-treatment"><i class="fa fa-check"></i><b>5.1</b> 二元 treatment</a></li>
<li class="chapter" data-level="5.2" data-path=""><a href="#%E5%A4%9A%E5%85%83treatment"><i class="fa fa-check"></i><b>5.2</b> 多元treatment</a></li>
<li class="chapter" data-level="5.3" data-path=""><a href="#%E8%BF%9E%E7%BB%ADtreatment"><i class="fa fa-check"></i><b>5.3</b> 连续treatment</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path=""><a href="#%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86"><i class="fa fa-check"></i><b>6</b> 数据收集</a>
<ul>
<li class="chapter" data-level="6.1" data-path=""><a href="#rct%E6%95%B0%E6%8D%AE"><i class="fa fa-check"></i><b>6.1</b> RCT数据</a></li>
<li class="chapter" data-level="6.2" data-path=""><a href="#%E8%A7%82%E6%B5%8B%E6%95%B0%E6%8D%AE"><i class="fa fa-check"></i><b>6.2</b> 观测数据</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path=""><a href="#%E7%BA%A0%E5%81%8F"><i class="fa fa-check"></i><b>7</b> 纠偏</a>
<ul>
<li class="chapter" data-level="7.1" data-path=""><a href="#%E5%B8%B8%E8%A7%81%E5%81%8F%E5%B7%AE"><i class="fa fa-check"></i><b>7.1</b> 常见偏差</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path=""><a href="#%E8%AF%84%E4%BC%B0"><i class="fa fa-check"></i><b>8</b> 评估</a>
<ul>
<li class="chapter" data-level="8.1" data-path=""><a href="#auuc"><i class="fa fa-check"></i><b>8.1</b> AUUC</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path=""><a href="#%E5%B8%B8%E8%A7%81%E5%AE%9A%E4%B9%89"><i class="fa fa-check"></i><b>8.1.1</b> 常见定义</a></li>
<li class="chapter" data-level="8.1.2" data-path=""><a href="#%E5%BD%92%E4%B8%80%E5%8C%96auuc"><i class="fa fa-check"></i><b>8.1.2</b> 归一化auuc</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path=""><a href="#qini_score"><i class="fa fa-check"></i><b>8.2</b> QINI_SCORE</a></li>
<li class="chapter" data-level="8.3" data-path=""><a href="#aucc"><i class="fa fa-check"></i><b>8.3</b> AUCC</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path=""><a href="#%E6%A0%A1%E5%87%86"><i class="fa fa-check"></i><b>9</b> 校准</a>
<ul>
<li class="chapter" data-level="9.1" data-path=""><a href="#%E5%BA%8F%E5%87%86"><i class="fa fa-check"></i><b>9.1</b> 序准</a></li>
<li class="chapter" data-level="9.2" data-path=""><a href="#%E5%80%BC%E5%87%86"><i class="fa fa-check"></i><b>9.2</b> 值准</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path=""><a href="#%E9%A2%84%E7%AE%97%E5%88%86%E9%85%8D"><i class="fa fa-check"></i><b>10</b> 预算分配</a>
<ul>
<li class="chapter" data-level="10.1" data-path=""><a href="#%E7%A6%BB%E7%BA%BF%E9%A2%84%E7%AE%97%E5%88%86%E7%B1%BB"><i class="fa fa-check"></i><b>10.1</b> 离线预算分类</a></li>
<li class="chapter" data-level="10.2" data-path=""><a href="#%E5%AE%9E%E6%97%B6%E9%A2%84%E7%AE%97%E5%88%86%E9%85%8D"><i class="fa fa-check"></i><b>10.2</b> 实时预算分配</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">因果模型学习笔记</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">因果模型学习笔记</h1>
<p class="author"><em>高文欣</em></p>
<p class="date"><em>2025-09-22</em></p>
</div>
<div id="le_uplift" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">1</span> le_uplift<a href="#le_uplift" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>找到真正能被营销手段激励的人群，在成本有限的情况下最大化营销的总产出。
<img src="refs/1.jpg" alt="因果图" /></p>
<p>对人群做四象限的划分，横纵坐标分别是用户在有干预和无干预情况下的购买状况，左上角人群的购买状况在干预后发生了正向变化，如果不对这类人群进行干预，那他有可能是不购买的，但是干预之后的购买概率有极大提升，所以这类人群是我们真正想要触达的用户，即营销敏感人群。而其他人群比如第2类和第3类，在干预前后的购买状况没有变化，所以预算花费可能是浪费。右下角是一类比较特殊的人群，虽然其在干预前后的状态有跳变，但这种跳变不是我们希望看到的，因为确实有一些人群对营销是反感的，所以对这类人群我们应该极力避免触达。Uplift Model正是为了识别我们想要的营销敏感人群。</p>
</div>
<div id="uplift-model与response-model区别" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">2</span> uplift-model与response-model区别<a href="#uplift-model%E4%B8%8Eresponse-model%E5%8C%BA%E5%88%AB" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<ul>
<li>Response Model的目标是估计用户看过广告之后转化的概率，这本身是一个相关性，但这个相关性会导致我们没有办法区分出自然转化人群；</li>
<li>Uplift Model是估计用户因为广告而购买的概率，这是一个因果推断的问题，帮助我们锁定对营销敏感的人群。所以UpliftModel是整个智能营销中非常关键的技术，预知每个用户的营销敏感程度，从而帮助我们制定营销策略，促成整个营销的效用最大化。</li>
</ul>
<p>举个栗子</p>
<div class="float">
<img src="refs/2.png" alt="模型差异" />
<div class="figcaption">模型差异</div>
</div>
<blockquote>
<p>以往经验可能会向第二类用户群投放广告，因为其转换率是最高的，但这个结论是对的吗？经过进一步分析，除了广告曝光转化率之外们还能知道这两类用户群体在没有广告触达情况下的自然转化率，从而推算出广告所带来的增量。比如第一类用户的广告转化率虽然低，但在没有广告触达情况下的转化率更低，即广告所带来的增量反而是比第二个用户更高的，而我们要最大化总体的转化率其实等价于最大化广告的增量，按照这个逻辑，我们应该向第一个用户投放广告。也就是说Response Model很有可能会误导我们做出错误的决策，Uplift Model和Response Model之所以有差异，主要在于两个模型的预测目标不一样。<a href="https://zhuanlan.zhihu.com/p/599355166">例子参考</a></p>
</blockquote>
<ul>
<li>uplift模型原理</li>
</ul>
<p>uplift模型的本质是对cate或者het函数关系的估计，就是在于找到给定某一个<span class="math inline">\(X\)</span>的情况下，<span class="math inline">\(Y\)</span>和<span class="math inline">\(T\)</span>的真实的映射关系。</p>
<p>机器学习模型通常是直接预测某个结果概率。Uplift模型则预测个体对干预的反应，即干预是否有效，效果如何。Uplift模型需要同时包含干预组（接受干预）和对照组（未接受干预）的数据，并且每个个体的响应变量（如购买、点击等）和干预标记（即是否接受干预）都要被记录。</p>
<p>所以，Uplift模型要基于干预组的样本特征和标记进行一次模型训练，基于对照组的样本特征和标记也要训练一次。这个训练过程的模型，便可以采用CART树，GBDT，逻辑回归等机器学习模型。</p>
<p>下面我们抽象出 Uplift 模型的数学表达形式，假设我们有一个二元变量T代表是否接受干预：</p>
<ul>
<li><p><span class="math inline">\(T=1\)</span> ：用户被干预（如收到促销短信、电话营销等）</p></li>
<li><p><span class="math inline">\(T=0\)</span> ：用户未被干预（对照组）</p></li>
</ul>
<p>目标变量 <span class="math inline">\(Y\)</span> 表示用户的转化情况：</p>
<ul>
<li><p><span class="math inline">\(Y=1\)</span> ：用户转化（如购买）</p></li>
<li><p><span class="math inline">\(Y=0\)</span> ：用户未转化</p></li>
</ul>
<p>针对构建好的预测模型，预测样本在接受干预和未接受干预情况下的结果概率。假设 <span class="math inline">\(Y_1\)</span> 是个体接受干预后的结果，<span class="math inline">\(Y_0\)</span> 是个体未接受干预时的结果。Uplift模型的目标是预测，因干预产生的增益为：</p>
<p><span class="math display">\[
\operatorname{Uplift}(x)=P(Y=1 \mid T=1, X=x)-P(Y=1 \mid T=0, X=x)
\]</span></p>
<p>其中，<span class="math inline">\(X\)</span> 是个体特征。 <span class="math inline">\(P(Y=1 \mid T=1, X=x)\)</span> 是个体在接受干预时发生某一事件的概率，<span class="math inline">\(P(Y=1 \mid T=0, X=x)\)</span> 是个体在没有干预时发生该事件的概率。</p>
<p><strong>这个公式本质，即给定某个用户特征 <span class="math inline">\(X\)</span>，在样本特征情况下，计算该用户在接受干预和未接受干预情况下的转化率差值。这个差值代表了干预的真实增量贡献。</strong></p>
<p>Uplift 模型的核心是估计 <span class="math inline">\(P(Y=1 \mid T=1, X)\)</span> 和 <span class="math inline">\(P(Y=1 \mid T=0, X)\)</span> 之间的差异。常见建模方法主要有以下几种。</p>
<p>（1）单模型法</p>
<p>将干预组和对照组数据，合并在一起，训练一个模型，这时干预动作 <span class="math inline">\(T\)</span> ，也作为一个特征纳入整个训练过程。训练模型，可以选择CART，逻辑回归，GBDT等模型。模型最终进行预测输出时，对每一个样本，输出</p>
<p><span class="math display">\[
\operatorname{Uplift}(x)=P(Y=1 \mid T=1, X)-P(Y=1 \mid T=0, X)
\]</span></p>
<p>作为最终Uplift计算结果值。</p>
<p>（2）双模型法</p>
<p>对干预组和对照组，两份数据集，分别建立两个独立的模型：</p>
<ul>
<li><p>模型 1 （对照组）训练目标为 <span class="math inline">\(P(Y=1 \mid T=0, X)\)</span></p></li>
<li><p>模型 2 （干预组）训练目标为 <span class="math inline">\(P(Y=1 \mid T=1, X)\)</span></p></li>
</ul>
<p>两个模型训练完成后，用两个模型分别同一样本在干预和不干预的情况下进行预测，计算两者的差值 作为 Uplift 评分</p>
<p><span class="math display">\[
\operatorname{Uplift}(x)=P(Y=1 \mid T=1, X)-P(Y=1 \mid T=0, X)
\]</span></p>
<p>作为最终Uplift计算结果值。</p>
</div>
<div id="基础定义" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">3</span> 基础定义<a href="#%E5%9F%BA%E7%A1%80%E5%AE%9A%E4%B9%89" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<ul>
<li><p>HTE heterogeneous treatment effect： 基于实验或者观测研究，检验不同子组样本之间的干预差异</p></li>
<li><p>反事实结果</p></li>
</ul>
<p>对于个体 <span class="math inline">\(i\)</span> ，从历史数据中不可能同时观测到对该样本的两种潜在结果 <span class="math inline">\(\tau_1\)</span> 和 <span class="math inline">\(\tau_2\)</span> ，因此对于处理效应的计算无法直接通过 <span class="math inline">\(Y_i(1)-Y_i(0)\)</span> 获得</p>
<p>在样本数据中我们观测到的结果只是个体 <span class="math inline">\(i\)</span> 获得某种处理状态后对应的潜在结果 <span class="math inline">\(Y_i\)</span> ，因此 <span class="math inline">\(Y_i\)</span> 可表示为：</p>
<p><span class="math display">\[
Y_i=Y_i(0)+\left[Y_i(1)-Y_i(0)\right] \times T_i
\]</span></p>
<p>假设总共有 <span class="math inline">\(M\)</span> 个样本，处理组 <span class="math inline">\(\left(T_i=1\right)\)</span> 内共有 <span class="math inline">\(K\)</span> 个样本，控制组 <span class="math inline">\(\left(T_i=0\right)\)</span> 内有 <span class="math inline">\(M-K\)</span> 个样本</p>
<p>对于处理组个体，我们只能获得潜在结果 <span class="math inline">\(Y_i(1)\)</span> ，而不能获得 <span class="math inline">\(Y_i(0)\)</span> 。因果推断中，一般将未观测到的潜在结果，即与观测结果 <span class="math inline">\(Y_i\)</span> 对应的另一为观测的潜在结果称为反事实结果。也就是说，对于处理组个体，其个体观测结果和反事实结果分别为 <span class="math inline">\(Y_i=Y_i(1)\)</span> 和 <span class="math inline">\(Y_i=Y_i(0)\)</span> ；控制组则恰好相反。</p>
<ul>
<li>ATE：平均处理效应，如AB实验，受处理和未受处理的人群的效果的差的期望</li>
</ul>
<p><span class="math display">\[
A T E=E[Y(1)-Y(0)]
\]</span></p>
<p>其中，<span class="math inline">\(Y(1)\)</span> 表示个体接受治疗时的潜在结果，<span class="math inline">\(Y(0)\)</span>表示个体未接受治疗时的潜在结果。ATE提供了一个总体层面上，治疗对结果影响的平均度量，不考虑个体的特征差异。例如，在研究一种新药物对所有患者的疗效时，ATE就是所有患者中，服用药物后的平均康复情况与不服用药物时的平均康复情况的差值。</p>
<ul>
<li><p>ATT：受处理的人群的平均处理效应，受处理的人群通过PSM方法找出和他们一样的人做为替身，看他们的效果的差别</p></li>
<li><p>CATE：人群中某个subgroup的平均处理效应</p></li>
</ul>
<p>CATE（条件平均治疗效应）：考虑了个体特征<span class="math inline">\(X\)</span>，是指在具有特定特征<span class="math inline">\(X=x\)</span>的子群体中，接受治疗和未接受治疗的个体之间，结果变量的平均差异。数学表达式为：</p>
<p><span class="math display">\[
\operatorname{CATE}(x)=E[Y(1)-Y(0) \mid X=x]
\]</span></p>
<p>它反映了在给定特征 <span class="math inline">\(x\)</span> 的条件下，治疗对结果的平均影响。例如，在上述新药物研究中，CATE 可以用来分析具有特定年龄、性别、基础疾病等特征组合的患者群体，服 <span class="math inline">\({ }^{-}\)</span>物和不服用药物时康复情况的平均差异。</p>
<ul>
<li>ITE：个体的因果效应，也可以看成是个体的CATE</li>
</ul>
</div>
<div id="模型" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> 模型<a href="#%E6%A8%A1%E5%9E%8B" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="meta-learner" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> meta-learner<a href="#meta-learner" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="slearner" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Slearner<a href="#slearner" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>s 顾名思义：single model，就是一个模型都搞定
这个模型最简单，直接把treatment作为特征放进模型来预测。首先我们把 T 作为特征一起放进机器学习模型的特征， Y 是目标，然后训练一个有监督的模型 <span class="math inline">\(\mu(x)=E[Y \mid X=x, T=t]\)</span> 。然后我们改变 T 的值，就可以得到两个不同的结果，再一相减就好了：
<span class="math display">\[\hat{\tau}(x)=\hat{\mu}(x, T=1)-\hat{\mu}(x, T=0)\]</span>
<img src="refs/slearner.jpg" /></p>
<p>优点：简单</p>
<p>缺点：</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>本质上还是不是对 uplift 直接进行建模，因此从效果上来说还是有提升空间。</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>S-Learner 倾向于将干预效果趋近于0，尤其是特征的维度非常大的时候，模型在训练的过程中极容易忽略这个干预变量。同时模型中正则化的引入，也会带来干预变量的效果稀释，正则化越强，该问题就会越大。</li>
</ol></li>
</ul>
<p>代码</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"></code></pre></div>
</div>
<div id="tlearner" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> TLearner<a href="#tlearner" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>T 顾名思义：two model 需要用俩模型（可以是任何的response模型）</p>
<p>对于 treatment 组的样本和 control 组的样本分别独立训练一个响应模型 <span class="math inline">\(\hat{\mu}_1(x)\)</span>和 <span class="math inline">\(\hat{\mu}_0(x)\)</span> 。其中 <span class="math inline">\(\hat{\mu}_1(x)\)</span> 用于拟合在施加干预的情况下响应目标 <span class="math inline">\(Y\)</span> 与特征 <span class="math inline">\(X\)</span> 的关系，即 <span class="math inline">\(\mu_1(x)=E[Y \mid W=1, X=x]\)</span> ；而 <span class="math inline">\(\hat{\mu}_0(x)\)</span> 用于拟合在未施加干预的情况下响应目标 <span class="math inline">\(Y\)</span>与特征 <span class="math inline">\(X\)</span> 的关系，即 <span class="math inline">\(\mu_0(x)=E[Y \mid W=0, X=x]\)</span> 。</p>
<p>之后拿训练好的两个模型对于同一个样本 <span class="math inline">\(x\)</span> 的预测结果做差，就得到了 uplift 结果。</p>
<p>最终得到的 T－Learner 表达式为 <span class="math inline">\(\hat{\tau}_T(x)=\hat{\mu}_1(x)-\hat{\mu}_0(x)\)</span>
下面是 T－Learner 算法的示意图（参考 Causal Inference for The Brave and True 这本书，因此该图部分 notation 与上文存在差异：图中的 T 对应上文的干预 <span class="math inline">\(W\)</span> ；图中的 M1和 M 0 对应上文的响应模型 <span class="math inline">\(\hat{\mu}_1\)</span> 和 <span class="math inline">\(\hat{\mu}_0\)</span> ）<a href="https://zhuanlan.zhihu.com/p/682079211">参考</a></p>
<p><img src="refs/tlearner.jpg" /></p>
<p>优点：可以灵活地使用已有的机器学习方法。对干预和非干预样本分别建模，充分考虑了干预因素的影响。</p>
<p>缺点：</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>T-Learner 并不是直接对 uplift 进行建模，因此对 uplift 的识别能力有限。</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>考虑到其基于两个独立训练的模型进行二次处理后来对 uplift 进行预测，很容易产生两个独立模型的误差累积的问题。</li>
</ol></li>
</ul>
</div>
<div id="xlearner" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> XLearner<a href="#xlearner" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>1．参考T-learner的思路，先对于 <span class="math inline">\(T=0\)</span> 的control组和 <span class="math inline">\(T=1\)</span> 的treatment组分别学习一个有监督的模型。
<img src="refs/xlearner2.jpg" alt="xlearner" /></p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mu_0(x)=E\left[Y^0 \mid X=x\right] \\
&amp; \mu_1(x)=E\left[Y^1 \mid X=x\right]
\end{aligned}
\]</span></p>
<p>2．然后对于 <span class="math inline">\(\mathrm{T}=1\)</span> 的样本和 <span class="math inline">\(\mathrm{T}=0\)</span> 的样本，分别使用 <span class="math inline">\(\mu_0(x)\)</span> 和 <span class="math inline">\(\mu_1(x)\)</span> 预测一个 <span class="math inline">\(\hat{\mu}^0\left(X^1\right)\)</span> 和 <span class="math inline">\(\hat{\mu}^1\left(X^0\right)\)</span> ，这里 <span class="math inline">\(X^0, X^1\)</span> 分别是 <span class="math inline">\(\mathrm{T}=0, \mathrm{~T}=1\)</span> 组 的样本，这步就是就是获得一个反事实的结果 （比如对于某一个 <span class="math inline">\(\mathrm{T}=1\)</span> 的样本 <span class="math inline">\(X_i^1\)</span> ，事实结果是 <span class="math inline">\(Y_i^1\)</span> ，反事实结果是 <span class="math inline">\(\hat{\mu}^0\left(X_i^1\right)\)</span> 。于是我们就可以对于control组和treatment组分别计算difference <span class="math inline">\(D_i^0\)</span> 和 <span class="math inline">\(D_i^1\)</span> ：</p>
<p><span class="math display">\[
\begin{aligned}
D_i^1 &amp; =Y_i^1-\hat{\mu}^0\left(X_i^1\right) \\
D_i^0 &amp; =\hat{\mu}^1\left(X_i^0\right)-Y_i^0
\end{aligned}
\]</span></p>
<p>3．最终对于一个新样本的CATE就是这两个的加权平均，权重是什么呢？一般是propensity score <span class="math inline">\(g(x)=P(T=1 \mid X=x)\)</span> ，这个可以通过一个LR模型或者任何二分类模型得到得到。最后新样本的的CATE如下：<span class="math inline">\(\hat{\tau}(x)=g(x) \hat{\tau}_0(x)+(1-g(x)) \hat{\tau}_1(x)\)</span></p>
<p><img src="refs/xlearner.jpg" alt="xlearner" />
下面是 X－Learner 算法的示意图（同样参考 Causal Inference for The Brave and True 这本书，图中 notation 与上文存在差异：图中的 T 对应上文的干预 <span class="math inline">\(W\)</span> ；图中的 M0 和 M1对应前面的模型 <span class="math inline">\(\hat{\mu}_0\)</span> 和 <span class="math inline">\(\hat{\mu}_1\)</span> ；图中的 MTAU0 和 MTAU1 对应前面的模型 <span class="math inline">\(\hat{\tau}_0\)</span> 和 <span class="math inline">\(\hat{\tau}_1\)</span> ）<a href="https://zhuanlan.zhihu.com/p/682079211">参考</a></p>
</div>
<div id="rlearner" class="section level3 hasAnchor" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> RLearner<a href="#rlearner" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
</div>
<div id="tree-base" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Tree-base<a href="#tree-base" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>传统机器学习模型中，树模型主要的思路就是通过对特征点进行分裂，将X划分到一个又一个subspace中，这与补贴场景下，希望找到某一小部分增量很高的用户的想法几乎是完美重合。</p>
<p>传统分类树模型是希望通过信息理论(information theory)中的信息熵等思想，用计算信息增益的方法去解决分类问题。而在uplift tree model中，其本质也还是想要通过衡量分裂前后的变量差值去决策是否分裂节点，不过这里的这个决策差值的计算方法不再是信息增益(information gain)，而是不同的直接对增量uplift建模的计算方法，其中包括了利用分布散度对uplift建模和直接对uplift建模。</p>
<p>下面介绍三个Tree-Based算法，Uplift-Tree，CausalForest，CTS。</p>
<div id="casusaltree" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Casusaltree<a href="#casusaltree" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>causal tree <span class="math inline">\({ }^{+}\)</span>（honest tree）是一种直接对目标进行建模的方法，它改进了传统决策树的优化目标和指标分桶方式，以达到最大化分桶的异质性因果效应，同时调整误差的效果。</p>
<p>首先，它会把数据分成训练集和估计集，一部分训练集去构造树，另外一部分估计集去估计因果效应和方差。</p>
<p>传统决策树将SSE作为目标函数，而causal tree的目标函数如下：</p>
<p><span class="math display">\[
F\left(S_l\right)=N_l * \tau^2\left(S_l\right)-N_l\left(\frac{\operatorname{Var}\left(S_l, 1\right)}{p}+\frac{\operatorname{Var}\left(S_l, 0\right)}{1-p}\right)
\]</span></p>
<p>其中，前半部分代表实验组的treatment effect，后半部分代表实验组和对照组的 variance。</p>
<p>通俗理解构建causal tree的过程：首先将训练机划分为训练集和评估集两部分，用训练集训练生成一颗决策树，训练的目标函数同时考虑了实验效应（最大）和方差（最小）。然后用评估集来估计CATE作为该叶子结点的CATE，对于新样本将会用该CATE作为预测值。<a href="https://zhuanlan.zhihu.com/p/688168539">参考</a></p>
</div>
<div id="casusalforest" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> CasusalForest<a href="#casusalforest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>因果森林（Causal Forest）由 Susan Athey 和 Stefan Wager 等大牛提出（2019），本质是广义随机森林（GRF）在因果推断场景的特化应用。因果森林的核心思想在于将随机森林改造为一个专门用于估计异质性因果效应的强大工具。传统的回归树分裂准则是让数据集平均MSE最小化，因果森林是通过 uplift 增益导向的分裂准则，引导树结构主动寻找处理效应发生变化的边界，从而自适应地将样本划分为协变量和处理组／对照组都相对平衡的局部子群体（近似局部 RCT）。分裂标准表达式为：</p>
<p><span class="math display">\[
\Delta\left(C_1, C_2\right)=\frac{n_{C_1} n_{C_2}}{n_P^2}\left(\hat{\theta_{C_1}}-\hat{\theta_{C_2}}\right)^2
\]</span></p>
<p><span class="math inline">\(P\)</span>代表决策树父节点， <span class="math inline">\(C_1\)</span>和<span class="math inline">\(C_2\)</span>是分裂后的 2 个子节点，<span class="math inline">\(\theta\)</span> 是两个子集的平均处理效应。因为两个子集中既有 <span class="math inline">\(\mathrm{T}=1\)</span> 的样本，也有 <span class="math inline">\(\mathrm{T}=0\)</span> 的样本，所以可以计算出平均处理效应，即平均增益。<span class="math inline">\(n\)</span>代表各集合的样本数目。决策树分裂要求上述表达式的值最大化。</p>
<ul>
<li><span class="math inline">\(\Delta\left(C_1, C_2\right)\)</span> ：表示类别 <span class="math inline">\(C_1\)</span> 和 <span class="math inline">\(C_2\)</span> 之间的＂差异值＂，是整个公式要计算的核心结果。</li>
<li><span class="math inline">\(n_{C_1}\)</span> ：类别 <span class="math inline">\(C_1\)</span> 中的样本数量（或观测数）。</li>
<li><span class="math inline">\(n_{C_2}\)</span> ：类别 <span class="math inline">\(C_2\)</span> 中的样本数量（或观测数）。</li>
<li><span class="math inline">\(n_P\)</span> ：总体（或父群体、合并群体）的总样本数量（即 <span class="math inline">\(n_P=n_{C_1}+n_{C_2}\)</span> ，如果 <span class="math inline">\(C_1\)</span> 和 <span class="math inline">\(C_2\)</span> 是总体的仅有的两个子组）。</li>
<li><span class="math inline">\(\hat{\theta}_{C_1}\)</span> ：对类别 <span class="math inline">\(C_1\)</span> 中某个参数 <span class="math inline">\(\theta\)</span> 的估计值（比如均值、处理效应、概率等，具体含义由研究场景决定）。</li>
<li><span class="math inline">\(\hat{\theta}_{C_2}\)</span> ：对类别 <span class="math inline">\(C_2\)</span> 中参数 <span class="math inline">\(\theta\)</span> 的估计值。</li>
</ul>
<p>公式逻辑与意义
公式的核心是<strong><em>组间参数差异的加权平方</em></strong>，权重由＂组样本量占总体的比例＂决定：</p>
<ul>
<li>分子部分：<span class="math inline">\(n_{C_1} n_{C_2}\left(\hat{\theta}_{C_1}-\hat{\theta}_{C_2}\right)^2\)</span></li>
<li><span class="math inline">\(\left(\hat{\theta}_{C_1}-\hat{\theta}_{C_2}\right)^2\)</span> ：直接衡量两个组的参数估计值的＂平方差＂，差越大，组间差异越显著。</li>
<li><span class="math inline">\(n_{C_1} n_{C_2}\)</span> ：是对＂组样本量＂的加权——如果某组样本量很大，会让这部分权重更高，体现＂大样本组的差异更值得关注＂ （或更能代表群体特征）。</li>
<li>分母部分：<span class="math inline">\(n_P^2\)</span>
对分子的 “样本量加权” 做归一化，避免因总体样本量<span class="math inline">\(n_P\)</span>过大导致 <span class="math inline">\(Δ\)</span>数值无限制膨胀，让结果更具可比性。</li>
</ul>
<p>传统的回归树，叶子结点预测结果是叶子结点上样本的响应变量平均值。类似的，因果树预测的结果是，叶子结点上的平均 CATE，以发优惠券为例，叶子结点预测的结果就是该节点上发券样本的平均转化率－不发券样本的平均转化率。</p>
<p>因果森林对比随机森林的差异</p>
<table>
<colgroup>
<col width="13%" />
<col width="43%" />
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">差异点</th>
<th align="left">随机森林</th>
<th align="left">因果森林</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">目标</td>
<td align="left">目标是预测一个观测值的结果 Y（分类或回归）。<br>分裂准则（如基尼系数、信息增益、均方误差）旨在最大化节点内结果的同质性或最小化预测误差。</td>
<td align="left">核心目标直接是估计每个个体或相似群体（叶子节点）的处理效应 <span class="math inline">\(τ(x) = E[Y(1)-Y(0) \mid X=x]\)</span>。<br>它不再直接预测 Y，而是预测 <span class="math inline">\(Y(1) - Y(0)\)</span> 这个反事实差异。<br>森林中的每一棵树都旨在构建一个能将样本划分为处理效应尽可能同质的子群体（叶子节点）的结构。</td>
</tr>
<tr class="even">
<td align="left">分裂准则</td>
<td align="left">传统分裂准则（如 MSE）在存在处理变量T时，会倾向于选择那些能同时很好预测Y且与T 相关的变量（即混杂因素）。但这会导致分裂后的子节点内，处理组和对照组在协变量分布上仍然不平衡（混杂未完全消除），从而污染了处理效应的估计。</td>
<td align="left">因果森林的分裂准则专门设计用于最大化子节点间处理效应的异质性或最小化子节点内处理效应估计的方差，常用准则包括：<br>• 基于 CATE 差异最大化：在候选分裂点，计算分裂后左右子节点的 CATE（<span class="math inline">\(τ_L\)</span> 和 <span class="math inline">\(τ_R\)</span>）差异 <span class="math inline">\(|τ_L - τ_R|\)</span>，选择差异最大的变量和分裂点（驱动树寻找效应突变边界）；<br>• 基于负梯度（梯度提升视角）：将 CATE 估计视为优化问题，用处理效应损失函数（如均方处理效应误差）的负梯度作为伪残差，指导分裂方向以减少 CATE 估计误差。</td>
</tr>
<tr class="odd">
<td align="left">集成学习与Honest Estimation</td>
<td align="left">基于“bootstrap抽样+随机特征选择”构建多棵决策树，集成时直接对每棵树的预测结果（分类概率/回归值）取平均，无“分裂与效应估计的样本分离”设计，未针对因果效应优化无偏性。</td>
<td align="left">1. 集成逻辑：与随机森林类似，构建数百棵“因果树”，每棵树基于随机子样本+随机特征子集训练，引入随机性以降低方差；<br>2. 双重样本利用（Honest Estimation）：<br> • 训练样本（S1）：仅用于构建树结构（决定分裂规则），不参与效应计算；<br> • 估计样本（S2）：与S1无交集（或通过Out-of-bag抽样实现），仅“落入”已训练好的树的叶子节点，用于计算该节点的效应 <span class="math inline">\(τ_{leaf}\)</span>（处理组与对照组均值差）；<br>3. 核心优势：<br> • 防过拟合：避免用同一批样本（S1）既建结构又算效应，减少噪声导致的偏差；<br> • 无偏性：满足独立性条件时，可提供渐近无偏的CATE估计；<br>4. 最终预测：新样本输入所有因果树，取各树输出的 <span class="math inline">\(τ_{leaf}\)</span> 均值（或中位数）作为最终CATE结果，集成平均提升估计稳定性。</td>
</tr>
</tbody>
</table>
</div>
<div id="dml" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> DML<a href="#dml" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>DML（double machine learning）是指一种用于因果推断的方法，它结合了现代机器学习技术与传统计量经济学方法，旨在从观测数据中准确估计因果效应。具体来说，double machine learning（DML）通过两个独立的预测步骤来实现这一目标：</p>
<p>第一阶段：使用机器学习模型预测结果变量 Y 和处理变量 T 关于协变量 X 的值。这一过程涉及两个模型的训练：一个是预测Y，另一个是预测T。</p>
<p><span class="math display">\[
\begin{aligned}
&amp; Y^{\prime}=f_1(X)+\varepsilon \\
&amp; T^{\prime}=f_2(x)+\varepsilon
\end{aligned}
\]</span></p>
<p>第二阶段：计算第一阶段预测值与实际值的残差，即得到 Y 的残差和 T 的残差。这些残差去除了协变量X的影响。</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \Delta Y=Y-Y^{\prime} \\
&amp; \Delta T=T-T^{\prime}
\end{aligned}
\]</span></p>
<p>回归分析：最后，对这些残差进行线性回归，以估计处理变量 T 对结果变量 Y 的因果效应。</p>
<p><span class="math display">\[
\Delta Y=\mu(x) * \Delta T+\varepsilon
\]</span></p>
<p>最终 <span class="math inline">\(\mu(x)\)</span> 即为输出结果。
这种方法的核心在于构造＂正交化＂得分，即通过残差来消除协变量的混杂影响，从而实现无偏的因果效应估计。DML特别适用于高维数据和复杂非线性关系的情况，因为它能够利用灵活的机器学习模型来处理大量控制变量，同时保持估计的稳健性。将 DML里面的模型换成随机森林就是CausalForestDML。</p>
<p>总结</p>
<p>不同于传统的拟合Y
DML提出直接拟合ATE，并利用残差消偏
拟合目标</p>
<p><span class="math display">\[
\tilde{Y}_i=\tilde{T}_i * \tau\left(X_i\right)+\epsilon
\]</span></p>
<p>其中 <span class="math inline">\(\tilde{Y}_i=Y_i-\hat{Y}_i, \tilde{T}_i=T_i-\hat{T}_i\)</span>, where <span class="math inline">\(\hat{Y}_i=E\left[Y_i \mid X_i\right], \hat{T}_i=E\left[T_i \mid X_i\right]\)</span> 目标是最小化 <span class="math inline">\(|\epsilon| \tau\left(X_i\right)\)</span> 即 ate</p>
<p>通过cross－fitting降低偏差，样本分为不相交 <span class="math inline">\(\mathrm{n}(n \geq 2)\)</span> 份，保证估计残差和计算 <span class="math inline">\(\tau\left(X_i\right)\)</span> 的不是同一份数据为什么需要DML？</p>
<p>1．引入学习残差的uplift模型
2．消偏，消偏指的是消除观测样本由于confounder造成的偏差。</p>
</div>
<div id="drl" class="section level3 hasAnchor" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> DRL<a href="#drl" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>拟合目标为 3 个模型：</p>
<p>1．在给定 T 的条件下，预测 Y 的取值，即</p>
<p><span class="math display">\[
\hat{E}\left[Y \mid T_i, X_i\right]
\]</span></p>
<p>2．倾向性得分</p>
<p><span class="math display">\[
\pi\left(X_i\right)=\mathbb{P}\left(T=t \mid X_i\right)
\]</span></p>
<p>计算 <span class="math inline">\(Y_{i, t}\)</span> ：</p>
<p><span class="math display">\[
\hat{Y}_{i, t}=\hat{E}\left[Y \mid T_i=t, X_i\right]+\frac{Y_i-\hat{E}\left[Y \mid T_i=t, X_i\right]}{\pi\left(X_i\right)} * 1\left(T_i=t\right)
\]</span></p>
<p>建立ate模型 <span class="math inline">\(\hat{\tau}\)</span> ：</p>
<p><span class="math display">\[
\hat{\tau}\left(X_i\right)=\hat{Y}_{i, 1}-\hat{Y}_{i, 0}
\]</span></p>
<p>例如通常的treatment组和control组实验，一共3个模型 <span class="math inline">\(\hat{E}\left[Y \mid T_i, X_i\right], \pi\left(X_i\right), \tau\left(\hat{X}_i\right)\)</span>
和单纯的利用IPW的方式相比，多了一重保障，即使IPW计算错误，只要 <span class="math inline">\(E\left[Y_i \mid \hat{T}_i, X_i\right]\)</span> 计算正确，也能保证结果正确，这也是double roboust的原因。</p>
<p>取期望，化简略</p>
<p><span class="math display">\[
\begin{aligned}
&amp; E\left[\hat{Y}_{i, 1}-Y_1\right] \\
= &amp; \frac{E\left(T_i\right)-\pi\left(X_i\right)}{\pi\left(X_i\right)} *\left[E\left(Y_1\right)-\hat{E}\left[Y \mid T_i=1, X_i\right]\right]
\end{aligned}
\]</span></p>
<p>当满足倾向性得分正确时前项为 0 ，当满足预测Y正确时后项为 0
所以期望为 0
即 <span class="math inline">\(\hat{Y}_{i, 1}\)</span> 是 <span class="math inline">\(Y_1\)</span> 的无偏估计，同理 <span class="math inline">\(\hat{Y}_{i, 0}\)</span></p>
</div>
</div>
<div id="深度因果模型" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> 深度因果模型<a href="#%E6%B7%B1%E5%BA%A6%E5%9B%A0%E6%9E%9C%E6%A8%A1%E5%9E%8B" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="tarnet" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> TARNET<a href="#tarnet" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>深度因果模型的基础网络，很多后续的网络都是在此基础上拓展的.为了让神经网络学习到的表示相近，Shalit et al．（2017）提出了Treatment Agnostic Regression Network（TARNet）。它的思想很简单，神经网络整体为双头结构，然后像 multi－task一样的共享层去学习共有的信息表征 <span class="math inline">\(\phi(x)\)</span> ，再利用该共享表征去分别学习treated组和control的outcome结果。共享层其实就会在treated和control组的信息中进行tread off，从而达到一种balanced。
简言之：TARNet前半部分用的是整个数据集，但是在后两个分支分别用的是T=0和T=1的分组数据各自训练所属的分支。</p>
<p><img src="refs/tarnet.png" alt="tarnet" />
图a是T-Learner，图b是tarnet，其中tarnet在2元treatment的loss如下：<a href="https://zhuanlan.zhihu.com/p/603499723">参考</a>
<span class="math display">\[
\underset{h, \Phi}{\arg \min } \frac{1}{N} \sum_{i=1}^N \operatorname{MSE}(Y_i\left(T_i\right), \underbrace{h\left(\Phi\left(X_i\right), T_i\right)}_{\hat{Y}_i\left(T_i\right)})+\lambda \underbrace{\mathcal{R}(h)}_{L_2}
\]</span></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>def <span class="fu">regression_loss</span>(concat_true, concat_pred)<span class="sc">:</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>    y_true <span class="ot">=</span> concat_true[<span class="sc">:</span>, <span class="dv">0</span>]</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    t_true <span class="ot">=</span> concat_true[<span class="sc">:</span>, <span class="dv">1</span>]</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    y0_pred <span class="ot">=</span> concat_pred[<span class="sc">:</span>, <span class="dv">0</span>]</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>    y1_pred <span class="ot">=</span> concat_pred[<span class="sc">:</span>, <span class="dv">1</span>]</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>    loss0 <span class="ot">=</span> <span class="fu">tf.reduce_sum</span>((<span class="fl">1.</span> <span class="sc">-</span> t_true) <span class="sc">*</span> <span class="fu">tf.square</span>(y_true <span class="sc">-</span> y0_pred))</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>    loss1 <span class="ot">=</span> <span class="fu">tf.reduce_sum</span>(t_true <span class="sc">*</span> <span class="fu">tf.square</span>(y_true <span class="sc">-</span> y1_pred))</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>    return loss0 <span class="sc">+</span> loss1</span></code></pre></div>
</div>
<div id="dragonnet" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Dragonnet<a href="#dragonnet" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="efin" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> EFIN<a href="#efin" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="descn" class="section level3 hasAnchor" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> DESCN<a href="#descn" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>模型整体有两部分结构组成ESN网络+Xnetwork网络</p>
<div class="float">
<img src="refs/descn.png" alt="descn" />
<div class="figcaption">descn</div>
</div>
<p>解决的问题</p>
<ul>
<li><p>干预偏差问题 Treatment Bias： 即被干预Treatment组（实验组）和未干预Control 组（对照组）的分布是不同的。</p></li>
<li><p>样本不均衡问题 Sample Imbalance：干预的Treatment 组和未干预的Control 组样本差异大，样本不平衡。</p></li>
</ul>
<p>问题根源：Treatment Bias 和 Sample Imbalance 都源于非随机的观测数据。</p>
<p>Treatment Bias 是因为处理分配（W）与协变量也就是特这（X）和潜在结果（Y(0), Y(1)）不独立，即存在混淆变量。</p>
<p>Sample Imbalance 虽然有时是策略本身导致的（如只对1%的用户发券），但在非随机环境下，这种数量上的不平衡会加剧模型学习的难度。</p>
<p>理论上来说，RCT实验数据是可以一定程度避免这俩问题的。
本文方法的三个假设：</p>
<ul>
<li><p>一致性Consistency：<span class="math inline">\(y_i=y_i\left(w_i\right)\)</span> ，观测到的 <span class="math inline">\(y_i\)</span> 和 潜在的 <span class="math inline">\(y_i\left(w_i\right)\)</span> 是一致的，即干预对结果的影响是稳定的。</p></li>
<li><p>可忽略性Ignorability：<span class="math inline">\(Y(1), Y(0) \perp T \mid X\)</span> ，意思是没有其他未观察到的混淆变量存在；</p></li>
<li><p>重叠Overlap： <span class="math inline">\(0&lt;\pi(x)&lt;1\)</span> ，即干预的施加是不确定的，存在倾向性。</p></li>
</ul>
<p><strong>ITE的基本框架</strong></p>
<ol style="list-style-type: decimal">
<li>样本数据集定义</li>
</ol>
<p>令观察样本为<span class="math inline">\(D=\left\{y_i, x_i, w_i\right\}_{i=1}^n\)</span>：表示包含<span class="math inline">\(n\)</span>个样本的数据集，每个样本包含三个核心变量：
<span class="math inline">\(\mathrm{y}, \mathrm{x}, \mathrm{w}\)</span> 分别表示效果标签、特征、是否被干预。每一个样本的 <span class="math inline">\(y_i \in\{0,1\}\)</span> ，表示binary的 outcome；每一个样本的 <span class="math inline">\(w_i \in\{0,1\}\)</span> 表示binary的treatment，当 <span class="math inline">\(w_i=1\)</span> 表示有干预，当 <span class="math inline">\(w_i=0\)</span> 表示无干预。</p>
<p>被干预的倾向性得分估计表示为 <span class="math inline">\(\pi(x)=P(W=1 \mid X=x)\)</span> 。
<span class="math inline">\(T=\left\{i: w_i=1\right\}\)</span>:干预样本的集和 <span class="math inline">\(C=\left\{i: w_i=0\right\}\)</span> ：对照组的样本集和。</p>
<p>2．倾向性得分（Propensity Score）</p>
<ul>
<li><p>定义：<span class="math inline">\(\pi(x)=P(W=1 \mid X=x)\)</span> ，表示在给定特征 <span class="math inline">\(x\)</span> 的条件下，样本接受干预（ <span class="math inline">\(W=1\)</span> ）的概率。</p></li>
<li><p>作用：倾向性得分是因果推断中的重要工具，常用于平衡实验组和对照组的特征分布，减少混杂偏倚（confounding bias）。</p></li>
</ul>
<p>3．干预效应的核心定义</p>
<p>要估计干预对结果的影响，需明确两个条件期望：</p>
<ul>
<li><p>干预组响应（TR）：<span class="math inline">\(\mu_1(x)=\mathbb{E}(Y \mid W=1, X=x)\)</span>表示＂在特征为 <span class="math inline">\(x\)</span> 且接受干预（ <span class="math inline">\(W=1\)</span> ）的条件下，结果 <span class="math inline">\(Y\)</span> 的期望＂（即特征为 <span class="math inline">\(x\)</span> 的样本接受干预后的平均结果）。</p></li>
<li><p>对照组响应（CR）：<span class="math inline">\(\mu_0(x)=\mathbb{E}(Y \mid W=0, X=x)\)</span>表示＂在特征为 <span class="math inline">\(x\)</span> 且未接受干预（ <span class="math inline">\(W=0\)</span> ）的条件下，结果 <span class="math inline">\(Y\)</span> 的期望＂（即特征为 <span class="math inline">\(x\)</span> 的样本未接受干预后的平均结果）。</p></li>
</ul>
<p>4．个体处理效应（ITE）的估计</p>
<ul>
<li><p>ITE 的定义：<span class="math inline">\(\tau(x)=\mu_1(x)-\mu_0(x)\)</span>表示对于特征为 <span class="math inline">\(x\)</span> 的个体，接受干预与未接受干预的结果差异，即＂干预对该个体的净效应＂。</p></li>
<li><p>估计思路：</p></li>
</ul>
<p>1．通过建模分别估计 <span class="math inline">\(\mu_1(x)\)</span> 和 <span class="math inline">\(\mu_0(x)\)</span> ，得到估计值 <span class="math inline">\(\hat{\mu}_1(x)\)</span> 和<span class="math inline">\(\hat{\mu}_0(x)\)</span>（例如用回归模型分别拟合实验组和对照组的结果与特征的关系）。</p>
<p>2．计算估计的 ITE：<span class="math inline">\(\hat{\tau}(x)=\hat{\mu}_1(x)-\hat{\mu}_0(x)\)</span> ，即通过两个条件期望的估计值之差，近似个体的真实干预效应。</p>
<p><strong>ESN结构</strong></p>
<p>如fig1 中的a图</p>
<p>ESN（Entire Space Network）通过定义两个关键概率来实现全空间建模，分别是 Entire Space Treated Response（ESTR）和 Entire Space Control Response （ESCR）。其中，ESTR 表示为 <span class="math inline">\(P(Y, W=1 \mid X)\)</span> ，即给定特征 <span class="math inline">\(X\)</span> 时，有干预且结果为 <span class="math inline">\(Y\)</span> 的联合概率，若 <span class="math inline">\(Y\)</span> 表示是否转化，ESTR 就是有干预且转化的概率； ESCR 表示为 <span class="math inline">\(P(Y, W=0 \mid X)\)</span> ，即给定特征 <span class="math inline">\(X\)</span> 时，无干预且结果为 <span class="math inline">\(Y\)</span> 的联合概率，若 <span class="math inline">\(Y\)</span> 表示是否转化， ESCR 就是无干预且转化的概率。</p>
<p>和Two model类型的模型将实验组和对照组样本分别建模为两个模型不同，ESN受多目标模型的启发，通过共享层对不同的数据提取Embedding。然后对于每个数据计算倾向程度分Propensity Score，对实验组数据进入干预分支得到ESTR，对于对照组数据进入对照分支得到ESCR。</p>
<p>基于此，ESN 通过拟合 ESTR、ESCR 以及倾向性 <span class="math inline">\(\pi\)</span> 的观测标签得到相应损失函数，分别是倾向损失 <span class="math inline">\(L_\pi\)</span> 、ESTR损失 <span class="math inline">\(L_{ESTR}\)</span> 和 ESCR 损失 <span class="math inline">\(L_{ESCR}\)</span> 。其中， <span class="math inline">\(L_\pi=\frac{1}{n} \sum_i l\left(t_i, \hat{\pi}\left(x_i\right)\right)\)</span> ，用于拟合倾向性得分； <span class="math inline">\(L_{\text {ESTR }}=\frac{1}{n} \sum_i l\left(y_i \&amp; w_i, \hat{\mu}_1\left(x_i\right) \cdot \hat{\pi}\left(x_i\right)\right)\)</span> ，用于拟合有干预且结果为 <span class="math inline">\(Y\)</span> 的情况<span class="math inline">\(L_{E S C R}=\frac{1}{n} \sum_i l\left(y_i \&amp;\left(1-w_i\right), \hat{\mu}_0\left(x_i\right) \cdot\left(1-\hat{\pi}\left(x_i\right)\right)\right)\)</span>:用于拟合无干预且结果为<span class="math inline">\(Y\)</span>的情况</p>
<p>合并后得到：<span class="math inline">\(L_{E S N}=\alpha \cdot L_\pi+\beta_1 \cdot L_{E S T R}+\beta_0 \cdot L_{E S C R}\)</span></p>
<p><strong>Xnetwork</strong></p>
<p>如fig1中的图b</p>
<p>是基于X-learner改进得到的端到端学习方法，整体流程有点类似于将X-learner组合为一个端到端的学习方式，也存在交叉思路的设计。</p>
<p>通过共享层后，左右两个分支分别对干预组数据和对照组数据进行建模，中间的PTE
（Pseudo Treatment Effe）得到 <span class="math inline">\(\tau^{\prime}\)</span> 为干预带来的隐藏的效果，然后X－Network是怎么做交叉的才是其核心所在。</p>
<p>先定义Cross Treated Response 、 Cross Control Response 两个节点
Cross Treated Response <span class="math inline">\(\mu_1^{\prime}:=\mu_0+\tau^{\prime}\)</span>
Cross Control Response <span class="math inline">\(\mu_0^{\prime}:=\mu_1-\tau^{\prime}\)</span>
对于 Cross Treated Response，其实是把 <span class="math inline">\(\mu_0\)</span> 当作反事实（counterfactual）预测函数去预测（如果不干预会怎么样），然后加上 PTE Netwrok的 <span class="math inline">\(\tau^{\prime}\)</span> 获得有干预时的respond。</p>
<p>对于 Cross Control Response，则是把 <span class="math inline">\(\mu_1\)</span> 当作反事实（counterfactual）预测函数去预测 （如果干预会怎么样），然后减去 PTE Netwrok的 <span class="math inline">\(\tau^{\prime}\)</span> 以此得到无干预时的respond。</p>
<p>然后Cross Treated Response、Cross Control Response 分别对T、C数据集拟合，</p>
<p><span class="math display">\[
\begin{aligned}
L_{T R} &amp; =\frac{1}{|T|} \sum_{i \in T} l\left(y_i, \hat{\mu}_1\left(x_i\right)\right), \\
L_{C R} &amp; =\frac{1}{|C|} \sum_{i \in C} l\left(y_i, \hat{\mu}_0\left(x_i\right)\right), \\
L_{C r o s s T R} &amp; =\frac{1}{|T|} \sum_{i \in T} l\left(y_i, \hat{\mu}_1^{\prime}\left(x_i\right)\right) \\
&amp; =\frac{1}{|T|} \sum_{i \in T} l\left(y_i, \sigma\left(\sigma^{-1}\left(\hat{\mu}_0\left(x_i\right)\right)+\sigma^{-1}\left(\hat{\tau}^{\prime}\left(x_i\right)\right)\right),\right. \\
L_{C r o s s C R} &amp; =\frac{1}{|C|} \sum_{i \in C} l\left(y_i, \hat{\mu}_0^{\prime}\left(x_i\right)\right) \\
&amp; =\frac{1}{|C|} \sum_{i \in C} l\left(y_i, \sigma\left(\sigma^{-1}\left(\hat{\mu}_1\left(x_i\right)\right)-\sigma^{-1}\left(\hat{\tau}^{\prime}\left(x_i\right)\right)\right)\right.
\end{aligned}
\]</span>
逐一解释每个损失的含义</p>
<p>1．基础损失（直接响应预测）</p>
<p><span class="math display">\[
L_{T R}=\frac{1}{|T|} \sum_{i \in T} l\left(y_i, \hat{\mu}_1\left(x_i\right)\right)
\]</span></p>
<ul>
<li><p>含义：</p></li>
<li><p><span class="math inline">\(T\)</span> 是处理组（Treatment Group）样本集合，<span class="math inline">\(|T|\)</span> 是处理组样本数量。</p></li>
<li><p><span class="math inline">\(\hat{\mu}_1\left(x_i\right)\)</span> 是模型对处理组样本 <span class="math inline">\(x_i\)</span> 的响应预测（即干预后的结果）。</p></li>
<li><p><span class="math inline">\(l(\cdot, \cdot)\)</span> 是损失函数（如分类用交叉嫡、回归用 MSE），衡量预测值与真实标签 <span class="math inline">\(y_i\)</span> 的差异。</p></li>
<li><p>作用：直接学习＂处理组特征 <span class="math inline">\(x_i \rightarrow\)</span> 处理后结果 <span class="math inline">\(y_i\)</span>＂的映射。</p></li>
</ul>
<p><span class="math display">\[
L_{C R}=\frac{1}{|C|} \sum_{i \in C} l\left(y_i, \hat{\mu}_0\left(x_i\right)\right)
\]</span></p>
<ul>
<li>含义：</li>
<li><span class="math inline">\(C\)</span> 是对照组（Control Group）样本集合，<span class="math inline">\(|C|\)</span> 是对照组样本数量。
<span class="math inline">\(\hat{\mu}_0\left(x_i\right)\)</span> 是模型对对照组样本 <span class="math inline">\(x_i\)</span> 的响应预测（即未干预时的结果）。
作用：直接学习＂对照组特征 <span class="math inline">\(x_i \rightarrow\)</span> 未干预结果 <span class="math inline">\(y_i\)</span>＂的映射。</li>
</ul>
<p>2．交叉损失（反事实预测）</p>
<p><span class="math display">\[
\begin{aligned}
&amp; L_{\text {CrossTR }}=\frac{1}{|T|} \sum_{i \in T} l\left(y_i, \hat{\mu}_1^{\prime}\left(x_i\right)\right) \\
&amp; =\frac{1}{|T|} \sum_{i \in T} l\left(y_i, \sigma\left(\sigma^{-1}\left(\hat{\mu}_0\left(x_i\right)\right)+\sigma^{-1}\left(\hat{\tau}^{\prime}\left(x_i\right)\right)\right)\right)
\end{aligned}
\]</span></p>
<ul>
<li>含义：</li>
<li><span class="math inline">\(\hat{\mu}_1^{\prime}\left(x_i\right)\)</span> 是反事实预测：用对照组的预测结果 <span class="math inline">\(\hat{\mu}_0\left(x_i\right)\)</span> 加上＂处理效应＂<span class="math inline">\(\hat{\tau}^{\prime}\left(x_i\right)\)</span> ，模拟处理组的结果。</li>
<li><span class="math inline">\(\sigma(\cdot)\)</span> 是激活函数（如分类用 Sigmoid，回归可能不用），<span class="math inline">\(\sigma^{-1}(\cdot)\)</span> 是其逆函数（如 Sigmoid 逆是 Logit 变换）。</li>
<li>作用：让模型学习＂如果对照组样本 <span class="math inline">\(x_i\)</span> 被处理，结果会怎样＂（反事实推理）。通过强制模型用 <span class="math inline">\(\hat{\mu}_0+\tau^{\prime}\)</span> 预测处理组结果，约束处理效应 <span class="math inline">\(\tau^{\prime}\)</span> 的合理性。</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; L_{\text {CrossCR }}=\frac{1}{|C|} \sum_{i \in C} l\left(y_i, \hat{\mu}_0^{\prime}\left(x_i\right)\right) \\
&amp; =\frac{1}{|C|} \sum_{i \in C} l\left(y_i, \sigma\left(\sigma^{-1}\left(\hat{\mu}_1\left(x_i\right)\right)-\sigma^{-1}\left(\hat{\tau}^{\prime}\left(x_i\right)\right)\right)\right)
\end{aligned}
\]</span></p>
<ul>
<li><p>含义：</p></li>
<li><p><span class="math inline">\(\hat{\mu}_0^{\prime}\left(x_i\right)\)</span> 是反事实预测：用处理组的预测结果 <span class="math inline">\(\hat{\mu}_1\left(x_i\right)\)</span> 减去＂处理效应＂<span class="math inline">\(\hat{\tau}^{\prime}\left(x_i\right)\)</span> ，模拟对照组的结果。</p></li>
</ul>
<p>作用：让模型学习＂如果处理组样本 <span class="math inline">\(x_i\)</span> 未被处理，结果会怎样＂（反事实推理）。通过 <span class="math inline">\(\hat{\mu}_1-\tau^{\prime}\)</span> 约束处理效应 <span class="math inline">\(\tau^{\prime}\)</span> ，确保效应的一致性。</p>
<p>核心逻辑：反事实约束</p>
<ul>
<li><p>处理效应 <span class="math inline">\(\tau(x)\)</span> 的定义是：<span class="math inline">\(\tau(x)=\mu_1(x)-\mu_0(x)\)</span>（处理后结果－未处理结果）。</p></li>
<li><p>CrossTR／CrossCR 通过反事实假设，强制模型满足：<span class="math inline">\(\mu_1(x)=\mu_0(x)+\tau(x)\)</span>（处理组结果 <span class="math inline">\(=\)</span> 对照组结果 + 处理效应）</p></li>
</ul>
<p><span class="math inline">\(\mu_0(x)=\mu_1(x)-\tau(x)(\)</span> 对照组结果 <span class="math inline">\(=\)</span> 处理组结果 - 处理效应 <span class="math inline">\()\)</span>
－这种约束让模型学习到的处理效应 <span class="math inline">\(\tau(x)\)</span> 更可靠，避免效应预测与直接响应预测矛盾。</p>
<p>总结</p>
<ul>
<li><p>基础损失（ <span class="math inline">\(L_{T R}, L_{C R}\)</span> ）：直接学习＂处理／对照组特征 <span class="math inline">\(\rightarrow\)</span> 结果＂的映射。</p></li>
<li><p>交叉损失（ <span class="math inline">\(L_{\text {CrossTR }}, L_{\text {CrossCR }}\)</span> ）：通过反事实推理，约束＂处理效应 <span class="math inline">\(\tau^{\prime \prime}\)</span> 的合理性，让模型同时满足：</p></li>
<li><p>处理组结果 <span class="math inline">\(=\)</span> 对照组结果 + 处理效应</p></li>
<li><p>对照组结果 <span class="math inline">\(=\)</span> 处理组结果－处理效应</p></li>
<li><p>这种设计是 X－learner 的核心思想，通过反事实约束提升 <span class="math inline">\(5 \vee\)</span> 立预测的准确性，常用于因果推断、uplift modeling 等场景。</p></li>
</ul>
<p>公式中 <span class="math inline">\(\sigma^{-1}\)</span> 表示sigmoid的逆函数，实际上 Cross Treated Response、Cross Control Response 会对 <span class="math inline">\(\tau^{\prime}\)</span> 在 logit 层面做加减，这么做的优点有二：</p>
<p>1．避免数值范围截断：sigmoid 函数的输出范围固定在 <span class="math inline">\((0,1)\)</span> 之间，若直接在概率层面对 <span class="math inline">\(\tau^{\prime}\)</span> 进行加减，可能导致结果超出合理范围（如小于 0 或大于 1），需要额外的截断处理，这会丟失信息或引入偏差。而 logit 层面（ <span class="math inline">\(\sigma^{-1}\)</span> 的输出）是实数域，加减操作不会受边界限制，无需截断。</p>
<p>2．增强小效应信号的捕捉能力：sigmoid 函数的特性是两端斜率极低（接近 0 ），中间区域斜率较高。这意味着在概率接近 0 或 1 时，纵轴（概率）的微小变化对应横轴（logit）的较大变化。通过在 logit 层面操作 <span class="math inline">\(\tau^{\prime}\)</span> ，即使是很小的效应信号，也能通过 logit 空间的显著变化被模型捕捉，从而提升对微弱干预效果的识别能力。</p>
<p><strong>ESN</strong></p>
<p>整体结构如fig1中的图c
DESCN就是将上面ESN（处理Treatment bias的能力）和 X－network（处理Sample imbalance的能力）结合，结构如图（c），损失函数如下：</p>
<p><span class="math display">\[
\begin{aligned}
L_{D E S C N} &amp; =L_{E S N}+\gamma_1 \cdot L_{C r o s s T R}+\gamma_0 \cdot L_{\mathrm{CrossCR}} \\
&amp; =\alpha \cdot L_\pi+\beta_1 \cdot L_{E S T R}+\beta_0 \cdot L_{E S C R} \\
&amp; +\gamma_1 \cdot L_{C r o s s T R}+\gamma_0 \cdot L_{C r o s s C R}
\end{aligned}
\]</span>
效果对比
<img src="refs/descn-res.png" />
# 多目标多场景</p>
</div>
</div>
</div>
<div id="treatment类型" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">5</span> treatment类型<a href="#treatment%E7%B1%BB%E5%9E%8B" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="二元-treatment" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> 二元 treatment<a href="#%E4%BA%8C%E5%85%83-treatment" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="多元treatment" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> 多元treatment<a href="#%E5%A4%9A%E5%85%83treatment" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="连续treatment" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> 连续treatment<a href="#%E8%BF%9E%E7%BB%ADtreatment" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
</div>
<div id="数据收集" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">6</span> 数据收集<a href="#%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="rct数据" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> RCT数据<a href="#rct%E6%95%B0%E6%8D%AE" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="观测数据" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> 观测数据<a href="#%E8%A7%82%E6%B5%8B%E6%95%B0%E6%8D%AE" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
</div>
<div id="纠偏" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">7</span> 纠偏<a href="#%E7%BA%A0%E5%81%8F" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="常见偏差" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> 常见偏差<a href="#%E5%B8%B8%E8%A7%81%E5%81%8F%E5%B7%AE" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>归纳偏置</li>
</ul>
<p>对潜在结果<span class="math inline">\(Y_i(1)\)</span>和<span class="math inline">\(Y_i(0)\)</span>的预测误差，本质上是模型可以准确学习给定样本中的可泛化信息的程度</p>
<ul>
<li>选择（因果）偏置</li>
</ul>
<p>表示给定的数据中的非所及偏差可以多大程度被消除。
由于收集数据的方式（样本选择过程）导致样本不能代表目标总体，从而使分析结论产生偏差。</p>
<p>例子：</p>
<p>“幸存者偏差”：二战时，军方想加固飞机。他们检查返航飞机上的弹孔，发现机翼上弹孔多，机身和尾翼上弹孔少。于是有人建议加固机翼。但统计学家沃德指出：样本只包含了“成功返航”的飞机（这就是选择机制）。那些被击中机身和尾翼的飞机很可能没能返航，所以它们的损伤情况没被记录在内。真正的结论是：应该加固弹孔少的机身和尾翼，因为这些部位中弹的飞机更可能坠毁。</p>
<p>只在网站上对自愿填写的用户进行问卷调查，结果只能代表“愿意填写问卷的用户”这个群体，而不是全体用户。</p>
<ul>
<li>混淆偏置</li>
</ul>
<p>混淆因素是指同时影响自变量T(干预变量)和因变量Y(结果变量)的变量，它会使得我们观察到的T与Y之间的关系既包含真实的因果关系，也包含由混杂因素带来的虚假关联。</p>
<p>例子：</p>
<p>“冰淇淋销量越高，溺水人数越多”。这里，冰淇淋销量和溺水人数有相关性，但并非因果关系。天气温度是一个混淆变量：天热导致更多人买冰淇淋，同时也导致更多人游泳从而增加溺水风险。如果忽略“温度”，就会得出“吃冰淇淋导致溺水”的错误结论。</p>
</div>
</div>
<div id="评估" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">8</span> 评估<a href="#%E8%AF%84%E4%BC%B0" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>常见的分类损失或者回归损失（rmse、rmse、mape等）是用来评估预测值与真实值之间的误差，但是在因果推荐场景真实＂因果效应＂无法直接观测
因果效应 <span class="math inline">\(\tau=Y(1)-Y(0)\)</span> 是反事实差异：对同一个体，无法同时观测＂接受干预 <span class="math inline">\(Y(1)\)</span>＂和＂不接受干预 <span class="math inline">\(Y(0)\)</span>＂。而像MSE则需要＂真实值 <span class="math inline">\(y_{\text {true }}\)</span>＂，但 <span class="math inline">\(\tau\)</span> 没有直接的＂真实标签＂（只能观测到 <span class="math inline">\(Y(1)\)</span>或<span class="math inline">\(Y(0)\)</span>，但不同时存在）。另外传统损失关注＂结果本身＂，而非＂干预差异＂
假设用 MSE 评估 Uplift 模型：</p>
<ul>
<li><p>若模型预测＂用户 A 的 Uplift 为 +0.3 ＂（即发券比不发券多 <span class="math inline">\(30 \%\)</span> 购买率），但实际中，用户 <span class="math inline">\(A\)</span> 只被观测到＂发券后购买（ <span class="math inline">\(Y(1)=1\)</span> ）＂或＂不发券没购买 <span class="math inline">\((Y(0)=0)\)</span>＂——无法得到＂<span class="math inline">\(Y(1)-Y(0)=1-0=1\)</span>＂的真实值（因反事实不可观测）。</p></li>
<li><p>MSE 会错误地将＂结果 <span class="math inline">\(Y\)</span>＂当作＂效应 <span class="math inline">\(\tau\)</span>＂的标签，导致评估完全偏离因果目标。</p></li>
</ul>
<p>因此因果推荐场景常见的评估指标，按照不同类型的t进行划分</p>
<ul>
<li>ordinary treatment 或者category treatment 使用auuc、aucc、mult-auuc，qini score。</li>
</ul>
<p>连续的treatment：一般把连续t转化成多个分桶变成 ordinary treatment 或者category treatment再使用</p>
<p><strong><em>评估干预的差异化效果</em></strong>：Uplift 模型旨在估计不同个体接受干预（如发放优惠券、实施政策等）相较于不接受干预时，结果变量（如购买行为、健康状况改善等）的差异。AUUC 和 Qini Score 都能衡量模型对个体进行排序的能力，即模型能否将那些干预效果好的个体排在前面，从而帮助决策者优先对这些个体实施干预，提高资源利用效率 。例如在营销场景中，企业希望找到那些原本不太可能购买，但通过发放优惠券等干预措施会产生购买行为的客户，Uplift 模型利用 AUUC 或 Qini Score 进行评估，就可以判断模型识别这类客户的能力。</p>
<p><strong><em>反映模型的整体性能</em></strong>：这两个指标通过对不同样本排序下的干预效果进行综合考量，能够反映 Uplift 模型在整个样本空间上的性能。它们不仅仅关注模型在部分样本上的表现，而是基于模型对所有样本的排序结果，计算曲线下的面积来量化模型的优劣 。比如在评估一项教育政策对不同学生学习成绩提升的因果效应时，通过 AUUC 或 Qini Score 可以了解模型能否准确区分出哪些学生能从政策中受益更多。</p>
<div id="auuc" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> AUUC<a href="#auuc" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="常见定义" class="section level3 hasAnchor" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> 常见定义<a href="#%E5%B8%B8%E8%A7%81%E5%AE%9A%E4%B9%89" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>uplift_curve曲线的面积</p>
<p>1．模型预测后的数据</p>
<p>2．样本排序：将测试集的所有样本喂入训练好的 Uplift 模型，得到 Uplift Score，并根据 Uplift Score 对所有测试样本降序排序。</p>
<p>3．分桶计算累计增益：对排序后的样本进行分桶，每个桶的序号记为 <span class="math inline">\(t(t=1,2, \ldots, N)\)</span> 。计算每个桶的累计增益 <span class="math inline">\(f(t)\)</span> ，公式为 <span class="math inline">\(f(t)=\left(\frac{Y_t^T}{N_t^T}-\frac{Y_t^C}{N_t^C}\right)\left(N_t^T+N_t^C\right)\)</span> 。其中 <span class="math inline">\(Y_t^T\)</span> 和 <span class="math inline">\(Y_t^C\)</span> 分别表示桶 <span class="math inline">\(t\)</span> 中处理组和对照组的正样本数量，<span class="math inline">\(N_t^T\)</span> 和 <span class="math inline">\(N_t^C\)</span> 分别表示桶 <span class="math inline">\(t\)</span>中处理组和对照组的样本总数。</p>
<p>4．计算 AUUC：将所有桶的累计增益相加，即 <span class="math inline">\(A U U C=\sum_{t=1}^N f(t)\)</span> ，得到 Uplift 曲线下的面积，也就是 AUUC 值。</p>
<p>应用场景</p>
<ul>
<li><p>评估 Uplift 模型性能 <span class="math inline">\({ }^1\)</span> ：AUUC 可衡量 Uplift 模型对个体因果效应排序的准确性。AUUC值越高，说明模型越能将干预效果好的个体排在前面，即模型性能越好。通过比较不同 Uplift 模型的 AUUC 值，可以选择更优的模型用于实际应用。</p></li>
<li><p>营销场景 ：在营销活动中，可根据 Uplift 模型预测的 Uplift Score 对客户进行排序，选取 AUUC 值较高的模型所对应的排序靠前的客户群体施加营销干预，如发送优惠券等。这些客户通常是对营销活动更敏感的群体，能提高营销资源的利用效率，提升营销效果。</p></li>
<li><p>评估政策效果：在评估某项政策对不同个体或地区的影响时，若存在部分个体或地区受政策影响（处理组），部分不受影响 （对照组）的情况，可以使用 AUUC 指标。通过计算 AUUC，可量化政策对目标群体的实际影响效果，为政策的调整和优化提供依据。</p></li>
<li><p>分析数据集质量 <span class="math inline">\({ }^2\)</span> ：从 <span class="math inline">\(A \cup U C\)</span> 的值和相关曲线，可以了解当前数据集的质量。如果 <span class="math inline">\(A \cup U C\)</span> 值较低，可能意味着数据集存在问题，如处理组和对照组差异过大、特征选择不合理等，需要 <span class="math inline">\({ }^{\cdots}\)</span>－步优化数据集或调整特征。</p></li>
</ul>
</div>
<div id="归一化auuc" class="section level3 hasAnchor" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> 归一化auuc<a href="#%E5%BD%92%E4%B8%80%E5%8C%96auuc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>CausalML的复现是基于这种的</p>
<p>公式：<span class="math inline">\(V(k)=\left(\frac{R_T(D, k)}{N_T(D, k)}-\frac{R_C(D, k)}{N_C(D, k)}\right) \cdot\left(N_T(D, k)+N_C(D, k)\right)\)</span></p>
<p>各符号对应文档中的定义（基于中＂Uplift 曲线的定义＂）：</p>
<ul>
<li><p><span class="math inline">\(k\)</span> ：按 Uplift 模型分降序排序后，＂头部圈选样本＂的数量或比例（如前 1000 个样本、前 <span class="math inline">\(10 \%\)</span> 样本）；</p></li>
<li><p><span class="math inline">\(D\)</span> ：当前评估的数据集（如测试集）；</p></li>
<li><p><span class="math inline">\(N_T(D, k)\)</span> ：头部 <span class="math inline">\(k\)</span> 个样本中，处理组（实验组）的样本量（接受干预的样本数）；</p></li>
<li><p><span class="math inline">\(N_C(D, k)\)</span> ：头部 <span class="math inline">\(k\)</span> 个样本中，对照组的样本量（未接受干预的样本数）；</p></li>
<li><p><span class="math inline">\(R_T(D, k)\)</span> ：头部 <span class="math inline">\(k\)</span> 个样本中，处理组的累计转化数（如购买、激活等目标结果的正例数）；</p></li>
<li><p><span class="math inline">\(R_C(D, k)\)</span> ：头部 <span class="math inline">\(k\)</span> 个样本中，对照组的累计转化数。</p></li>
</ul>
<p>公式的计算逻辑可拆为两步：</p>
<p>1．计算头部 <span class="math inline">\(k\)</span> 个样本的＂处理组转化率先验差＂：<span class="math inline">\(\frac{R_T(D, k)}{N_T(D, k)}-\frac{R_C(D, k)}{N_C(D, k)}\)</span> ，即处理组平均转化减去对照组平均转化，衡量＂单位样本的 Uplift 增益＂；</p>
<p>2．乘以＂头部 <span class="math inline">\(k\)</span> 个样本的总数量＂<span class="math inline">\(\left(N_T(D, k)+N_C(D, k)\right)\)</span> ，将＂单位样本增益＂扩展为＂头部 <span class="math inline">\(k\)</span> 个样本的累计绝对增益＂—这一步是为了避免＂小样本分桶的增益被低估＂，让曲线能反映”圈选人群规模对应的实际收益”</p>
<p><strong><em>为何进行归一化操作</em></strong></p>
<ul>
<li>消除量纲对齐可比基准</li>
</ul>
<p>文档中提到的＂总 Uplift 收益因子 <span class="math inline">\(\left(V_r(K)\right)\)</span>＂和＂总样本量因子 <span class="math inline">\((K)\)</span>＂，是对 <span class="math inline">\(V(k)\)</span> 曲线的 X 轴（样本量）和 Y 轴（收益）进行归一化的核心，目的是解决＂不同数据集／样本量下 AUUC 不可比＂的问题（）。</p>
<p>1．总 Uplift 收益因子（ Y 轴归一化）：<span class="math inline">\(V_r(K)\)</span>
－定义：<span class="math inline">\(V_r(K)\)</span> 是＂全量样本（ <span class="math inline">\(k=K, K\)</span> 为总样本数）对应的累计绝对 Uplift 增益＂，即把 <span class="math inline">\(k=K\)</span> 代入 <span class="math inline">\(V(k)\)</span> 的结果：</p>
<p><span class="math display">\[
V_r(K)=\left(\frac{R_T(D, K)}{N_T(D, K)}-\frac{R_C(D, K)}{N_C(D, K)}\right) \cdot\left(N_T(D, K)+N_C(D, K)\right)
\]</span></p>
<p>－作用：作为 Y 轴的＂最大刻度基准＂一 将任意 <span class="math inline">\(k\)</span> 对应的 <span class="math inline">\(V(k)\)</span> 除以 <span class="math inline">\(V_r(K)\)</span> ，可把＂绝对收益＂转化为＂相对收益占比＂（如 <span class="math inline">\(V(k) / V_r(K)=0.6\)</span> ，表示头部 <span class="math inline">\(k\)</span> 个样本的收益占全量样本总收益的 <span class="math inline">\(60 \%\)</span> ），消除＂总收益规模差异＂的影响（）。</p>
<p>2．总样本量因子（X 轴归一化）：<span class="math inline">\(K\)</span>
- 定义：<span class="math inline">\(K\)</span> 是当前评估数据集的总样本数（即 <span class="math inline">\(k\)</span> 的最大值）；
- 作用：作为 X 轴的＂最大刻度基准＂一 将任意 <span class="math inline">\(k\)</span> 除以 <span class="math inline">\(K\)</span> ，可把＂绝对样本数＂转化为＂相对样本比例＂（如 <span class="math inline">\(k / K=0.3\)</span> ，表示头部 <span class="math inline">\(30 \%\)</span> 的样本），消除＂数据集大小差异＂的影响（）。</p>
<ul>
<li>让 AUUC 更具实用价值</li>
</ul>
<p>未归一化的 <span class="math inline">\(V(k)\)</span> 曲线存在明显缺陷：比如＂ 10 万样本的数据集＂和＂ 1 万样本的数据集＂，即使模型效果相同，前者的 <span class="math inline">\(V(k)\)</span> 绝对值也会更大，导致 AUUC 无法直接比较。</p>
<p>通过＂ X 轴 <span class="math inline">\(\div K 、 \mathrm{Y}\)</span> 轴 <span class="math inline">\(\div V_r(K)\)</span>＂的归一化后：</p>
<p>曲线的 X 轴范围固定为[0,1]（从 0 到 100% 的样本）；
曲线的 Y 轴范围固定为[0,1]（从 0 到 100% 的总收益）；
此时计算的 AUUC（归一化曲线下的面积）具有明确的参考意义：若模型效果 “等价于随机分配”，AUUC 约为 0.5（对应 “随机排序下的三角形面积”）；若模型效果优于随机，AUUC&gt;0.5，且值越大表示 “排序越精准、收益越集中在头部”</p>
<p>缺点：当Treatment组和Control组样本不一致时，其表达的增量存在偏差<a href="https://zhuanlan.zhihu.com/p/363082639">参考煎饼证</a></p>
</div>
</div>
<div id="qini_score" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> QINI_SCORE<a href="#qini_score" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>由于plift Curve存在一个问题，当Treatment组和Control组样本不一致时，其表达的增量存在偏差。因此对上式做一个缩放修改，相当于以Treatment组的样本量为准，对Control组做一个缩放，累积绘制的曲线称为Qini 曲线</p>
<p><span class="math display">\[
g(t)=Y_t^T-\frac{Y_t^C N_t^T}{N_t^C}
\]</span></p>
<p>此时有 <span class="math inline">\(f(t)=g(t) \frac{N_t^T+N_t^C}{N_t^T}\)</span></p>
</div>
<div id="aucc" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> AUCC<a href="#aucc" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>考虑成本的</p>
</div>
</div>
<div id="校准" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">9</span> 校准<a href="#%E6%A0%A1%E5%87%86" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="序准" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> 序准<a href="#%E5%BA%8F%E5%87%86" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="值准" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> 值准<a href="#%E5%80%BC%E5%87%86" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
</div>
<div id="预算分配" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">10</span> 预算分配<a href="#%E9%A2%84%E7%AE%97%E5%88%86%E9%85%8D" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="离线预算分类" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> 离线预算分类<a href="#%E7%A6%BB%E7%BA%BF%E9%A2%84%E7%AE%97%E5%88%86%E7%B1%BB" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="实时预算分配" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> 实时预算分配<a href="#%E5%AE%9E%E6%97%B6%E9%A2%84%E7%AE%97%E5%88%86%E9%85%8D" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><a href="https://gaowenxin95.github.io/learn_uplift_model/le_uplift.html" class="uri">https://gaowenxin95.github.io/learn_uplift_model/le_uplift.html</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": false,
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
